{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from common.encoding import *\n",
    "from common.neural_embedding import *\n",
    "from common.network_analysis import *\n",
    "from common.encoding import *\n",
    "from numpy.ma.core import shape\n",
    "\n",
    "from utils.file_utils import *"
   ],
   "id": "991c5fbf1dafb67d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Load data. ###",
   "id": "4f07f70af7707613"
  },
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Load edge list\n",
    "global_edge_table = pd.read_csv('data/processed_data/global_edge_list.csv')\n",
    "global_edge_list = list(global_edge_table.itertuples(index = False, name = None))\n",
    "\n",
    "print(len(global_edge_list))"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Train embedding neural network. ###",
   "id": "945741c93a2ed064"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:30:50.697230Z",
     "start_time": "2024-10-27T15:28:29.299181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List of (k_in, k_out)\n",
    "# k_list = [(1, 1),\n",
    "#           (2, 1),\n",
    "#           (3, 1),\n",
    "#           (5, 1),\n",
    "#           (10, 1)]\n",
    "\n",
    "k_list = [(3, 1),\n",
    "          (10, 1)]\n",
    "\n",
    "# embedding_vector_dim_list = [5, 10, 20, 30]\n",
    "embedding_vector_dim_list = [5, 20]\n",
    "\n",
    "# Training configurations.\n",
    "epoch_num = 15\n",
    "batch_size = 128\n",
    "\n",
    "file_directory = 'data/output_data/'\n",
    "\n",
    "k_to_loss_history = {}\n",
    "\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "for k in k_list:\n",
    "    filtered_edge_list = remove_low_degree_nodes(global_edge_list, k[0], k[1])\n",
    "    filtered_edge_list_df = pd.DataFrame(filtered_edge_list, columns=['followee', 'follower'])\n",
    "    edge_file_name = 'global_edge_list_kin' + str(k[0]) + '_kout' + str(k[1]) + '.csv'\n",
    "    save_to_csv(file_directory, edge_file_name, filtered_edge_list_df)\n",
    "    \n",
    "    # Obtain follower_map and followee map, which are dictionaries mapping usernames to integer values.\n",
    "    congress_map, followee_map = build_dict(filtered_edge_list)\n",
    "    \n",
    "    for embedding_vector_dim in embedding_vector_dim_list:\n",
    "        \"\"\"\n",
    "        network_input_dim = congress_map_length\n",
    "        network_hidden_dim = embedding_dim\n",
    "        network_output_dim = followee_map_length\n",
    "        \"\"\"\n",
    "        congress_map_length = len(congress_map)\n",
    "        followee_map_length = len(followee_map)\n",
    "        \n",
    "        print('Input dimension is ' + str(congress_map_length) + '.')\n",
    "        print('Hidden dimension is ' + str(embedding_vector_dim) + '.')\n",
    "        print('Output dimension is ' + str(followee_map_length) + '.')\n",
    "        \n",
    "        print('Training NN with k_in >=' + str(k[0]) + ', kout >=' + str(k[1]) + ' and embedding_vector_dim = ' + str(embedding_vector_dim) + ' ...')\n",
    "\n",
    "        # Build NN.\n",
    "        shallow_nn = ShallowNN(congress_map_length, embedding_vector_dim, followee_map_length)\n",
    "\n",
    "        # Training configurations.\n",
    "        loss_function = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(shallow_nn.parameters(), lr=0.001)\n",
    "\n",
    "        # Train NN and get loss value of every epoch.\n",
    "        loss_history = train_network(shallow_nn, epoch_num, batch_size, loss_function, \n",
    "                             optimizer, filtered_edge_list, congress_map, followee_map)\n",
    "        k_to_loss_history[k] = loss_history\n",
    "        \n",
    "        # Get weight matrix and bias.\n",
    "        input_to_hidden_weights = shallow_nn.linear_stack[0].weight.data\n",
    "        input_to_hidden_bias = shallow_nn.linear_stack[0].bias\n",
    "        \n",
    "        # Get congress-to-embedding dict and save.\n",
    "        # A congress list is needed to determine one hot vector length.\n",
    "        congress_list = [item[1] for item in filtered_edge_list]\n",
    "        _, congress_to_vector_dict = one_hot_encode(congress_list, congress_map)\n",
    "        user_to_embedding_dict = calculate_embeddings(congress_to_vector_dict, input_to_hidden_weights, input_to_hidden_bias)\n",
    "        \n",
    "        embedding_file_name = 'global_embedding_kin' + str(k[0]) + '_kout' + str(k[1]) + '_dim' + str(embedding_vector_dim) + '.pth'\n",
    "        save_to_pth(file_directory, embedding_file_name, user_to_embedding_dict)"
   ],
   "id": "59e759d7a6274ce5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension is 164.\n",
      "Hidden dimension is 5.\n",
      "Output dimension is 15661.\n",
      "Training NN with k_in >=3, kout >=1 and embedding_vector_dim = 5 ...\n",
      "Epoch [1/15], Loss: 9.6582\n",
      "Epoch [2/15], Loss: 9.6387\n",
      "Epoch [3/15], Loss: 9.5567\n",
      "Epoch [4/15], Loss: 9.4229\n",
      "Epoch [5/15], Loss: 9.2947\n",
      "Epoch [6/15], Loss: 9.1944\n",
      "Epoch [7/15], Loss: 9.1170\n",
      "Epoch [8/15], Loss: 9.0561\n",
      "Epoch [9/15], Loss: 9.0070\n",
      "Epoch [10/15], Loss: 8.9661\n",
      "Epoch [11/15], Loss: 8.9312\n",
      "Epoch [12/15], Loss: 8.9009\n",
      "Epoch [13/15], Loss: 8.8741\n",
      "Epoch [14/15], Loss: 8.8501\n",
      "Epoch [15/15], Loss: 8.8283\n",
      "Input dimension is 164.\n",
      "Hidden dimension is 20.\n",
      "Output dimension is 15661.\n",
      "Training NN with k_in >=3, kout >=1 and embedding_vector_dim = 20 ...\n",
      "Epoch [1/15], Loss: 9.6564\n",
      "Epoch [2/15], Loss: 9.5846\n",
      "Epoch [3/15], Loss: 9.3504\n",
      "Epoch [4/15], Loss: 9.1197\n",
      "Epoch [5/15], Loss: 8.9705\n",
      "Epoch [6/15], Loss: 8.8636\n",
      "Epoch [7/15], Loss: 8.7803\n",
      "Epoch [8/15], Loss: 8.7099\n",
      "Epoch [9/15], Loss: 8.6465\n",
      "Epoch [10/15], Loss: 8.5873\n",
      "Epoch [11/15], Loss: 8.5312\n",
      "Epoch [12/15], Loss: 8.4777\n",
      "Epoch [13/15], Loss: 8.4265\n",
      "Epoch [14/15], Loss: 8.3778\n",
      "Epoch [15/15], Loss: 8.3316\n",
      "Input dimension is 164.\n",
      "Hidden dimension is 5.\n",
      "Output dimension is 3012.\n",
      "Training NN with k_in >=10, kout >=1 and embedding_vector_dim = 5 ...\n",
      "Epoch [1/15], Loss: 8.0108\n",
      "Epoch [2/15], Loss: 8.0090\n",
      "Epoch [3/15], Loss: 8.0031\n",
      "Epoch [4/15], Loss: 7.9831\n",
      "Epoch [5/15], Loss: 7.9388\n",
      "Epoch [6/15], Loss: 7.8739\n",
      "Epoch [7/15], Loss: 7.8039\n",
      "Epoch [8/15], Loss: 7.7415\n",
      "Epoch [9/15], Loss: 7.6915\n",
      "Epoch [10/15], Loss: 7.6534\n",
      "Epoch [11/15], Loss: 7.6244\n",
      "Epoch [12/15], Loss: 7.6019\n",
      "Epoch [13/15], Loss: 7.5838\n",
      "Epoch [14/15], Loss: 7.5688\n",
      "Epoch [15/15], Loss: 7.5560\n",
      "Input dimension is 164.\n",
      "Hidden dimension is 20.\n",
      "Output dimension is 3012.\n",
      "Training NN with k_in >=10, kout >=1 and embedding_vector_dim = 20 ...\n",
      "Epoch [1/15], Loss: 8.0108\n",
      "Epoch [2/15], Loss: 8.0005\n",
      "Epoch [3/15], Loss: 7.9539\n",
      "Epoch [4/15], Loss: 7.8417\n",
      "Epoch [5/15], Loss: 7.7124\n",
      "Epoch [6/15], Loss: 7.6186\n",
      "Epoch [7/15], Loss: 7.5590\n",
      "Epoch [8/15], Loss: 7.5188\n",
      "Epoch [9/15], Loss: 7.4883\n",
      "Epoch [10/15], Loss: 7.4630\n",
      "Epoch [11/15], Loss: 7.4407\n",
      "Epoch [12/15], Loss: 7.4203\n",
      "Epoch [13/15], Loss: 7.4013\n",
      "Epoch [14/15], Loss: 7.3834\n",
      "Epoch [15/15], Loss: 7.3662\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Training results analysis. ###\n",
    "接下来应该画图，同一嵌入向量维度不同kin的对比，同一kin不同嵌入向量维度的对比，每次对比放在一张图中，先对比同kin的情况，后对比同一嵌入向量维度的情况。"
   ],
   "id": "14f00430618525e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:25:18.019374Z",
     "start_time": "2024-10-23T10:38:41.165869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# input_to_hidden_weights = shallow_nn.fc1.weight.data\n",
    "# print('The shape of input-to-hidden weight matrix is ' + str(input_to_hidden_weights.shape) + '.')\n",
    "# \n",
    "# input_to_hidden_bias = shallow_nn.fc1.bias.data\n",
    "# print('The shape of input-to-hidden bias is ' + str(input_to_hidden_bias.shape) + '.')\n",
    "# \n",
    "# input_to_hidden_weights_df = pd.DataFrame(input_to_hidden_weights)\n",
    "# input_to_hidden_bias_df = pd.DataFrame(input_to_hidden_bias)\n",
    "# \n",
    "# save_to_csv('data/output_data/', 'input_to_hidden_weights.csv', input_to_hidden_weights_df)\n",
    "# save_to_csv('data/output_data/', 'input_to_hidden_bias.csv', input_to_hidden_bias_df)"
   ],
   "id": "baaab56ce4aa6510",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of input-to-hidden weight matrix is torch.Size([20, 164]).\n",
      "The shape of input-to-hidden bias is torch.Size([20]).\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Obtain embedding vectors. ###",
   "id": "da0f5812969178c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T15:25:18.019505Z",
     "start_time": "2024-10-23T10:38:41.232540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Read congress member info\n",
    "# congress_member_info = pd.read_csv('data/raw_data/all_congress_members.csv')\n",
    "# congress_list = congress_member_info['twitter_name'].tolist()\n",
    "# \n",
    "# weights = torch.tensor(input_to_hidden_weights_df.values).float()\n",
    "# bias = torch.tensor(input_to_hidden_bias_df.values).float()\n",
    "# \n",
    "# congress_vectors, congress_to_vector_dict = one_hot_encode(congress_list, congress_map)\n",
    "# \n",
    "# congress_to_embedding_dict = {}\n",
    "# \n",
    "# # Throw this to encoding.py, as it can be seen as an encoding manipulation.\n",
    "# for congress_member in congress_list:\n",
    "#     if congress_member not in congress_to_vector_dict:\n",
    "#         continue\n",
    "#     \n",
    "#     vector = congress_to_vector_dict[congress_member]\n",
    "#     vector = torch.tensor(vector).float()\n",
    "#     vector = vector.unsqueeze(0)\n",
    "#     embedding_vector = torch.matmul(vector, weights.t()) + bias.squeeze()\n",
    "#     embedding_vector = embedding_vector.squeeze()\n",
    "#     \n",
    "#     congress_member_info.loc[congress_member_info['twitter_name'] == congress_member, 'embedding_vector'] = embedding_vector.tolist()\n",
    "#     \n",
    "# congress_one_hot_vectors = torch.stack(congress_vectors)\n",
    "# embedding_vectors = torch.matmul(congress_one_hot_vectors, weights.t()) + bias.squeeze()\n",
    "# \n",
    "# embedding_vectors_df = pd.DataFrame(embedding_vectors)\n",
    "# save_to_csv('data/output_data/', 'embedding_vectors.csv', embedding_vectors_df)\n",
    "# \n",
    "# print('The size of embedding vectors is ' + str(embedding_vectors_df.shape) + '.')"
   ],
   "id": "17ee8c8a839f1d02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of embedding vectors is (164, 20).\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
